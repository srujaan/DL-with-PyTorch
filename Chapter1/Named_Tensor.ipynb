{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named Tensor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA9hORiuTs0mOV/9SWldAa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz05XDKYOa6z"
      },
      "source": [
        "# Named Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hA-apIoQp17"
      },
      "source": [
        "##### Suppose we have 3D tensor of preprocessed image and convert it to grey scale. \n",
        "##### The weights can be found using https://en.wikipedia.org/wiki/Luma_(video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHA2put5RewI"
      },
      "source": [
        "import torch\n",
        "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
        "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL2O3hJ1RwVO",
        "outputId": "178fb2c4-bc43-4058-8550-e9bec0180046"
      },
      "source": [
        "# here we pretend to have a batch of 2:\n",
        "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]\n",
        "batch_t"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.4100, -1.3315,  0.0405,  1.3549,  1.0871],\n",
              "          [ 0.6455,  1.3359, -1.2811, -0.9266,  0.4168],\n",
              "          [ 1.0768, -0.1804,  0.1696,  0.5665, -0.6313],\n",
              "          [ 1.4229,  1.8907, -3.4759, -0.0354,  0.2929],\n",
              "          [ 1.9119,  0.5833, -0.0109, -1.0450,  0.2057]],\n",
              "\n",
              "         [[ 0.0319, -1.2357, -0.7350, -0.4682,  1.1221],\n",
              "          [ 0.8661,  0.8631,  0.5096,  0.4544,  1.3784],\n",
              "          [ 0.5872, -0.4808, -0.4743, -2.0545,  0.3749],\n",
              "          [-0.1347, -0.3108, -0.9702, -1.2456,  1.4473],\n",
              "          [-0.0213,  1.3130,  3.2319, -0.8864, -1.3342]],\n",
              "\n",
              "         [[-0.7277, -0.5777,  0.2528,  0.5586,  0.4245],\n",
              "          [-0.3194, -0.5288,  0.8137,  1.0721,  1.1479],\n",
              "          [ 0.3406, -1.8036, -1.0298, -0.8594,  0.1502],\n",
              "          [ 0.4280, -0.5345, -1.6014, -0.7111, -1.8620],\n",
              "          [ 0.8920,  1.8290, -0.9395, -0.9176, -1.8625]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0230, -0.3859, -0.2691, -0.2171,  2.8639],\n",
              "          [-0.1624,  0.3184,  0.8411,  1.6167,  0.8433],\n",
              "          [-1.3253, -0.4478, -0.0247,  1.0595, -0.1064],\n",
              "          [-0.4363, -1.8952,  0.0070,  1.9819, -0.0613],\n",
              "          [-1.1843,  0.4558,  0.2677,  0.2644, -0.4924]],\n",
              "\n",
              "         [[ 0.5471,  0.8789,  1.0587,  1.2009,  0.7666],\n",
              "          [ 0.1296,  0.2070,  0.8983,  0.5408, -1.0706],\n",
              "          [ 0.0155, -0.7126,  0.1371, -0.8831, -0.0549],\n",
              "          [-0.0463,  0.7873, -0.0955,  0.1151, -1.6797],\n",
              "          [-0.8577, -1.3944,  0.2506,  1.0648, -0.6486]],\n",
              "\n",
              "         [[ 0.5374,  1.2154,  0.8141,  0.6256, -0.8803],\n",
              "          [ 0.1967, -0.4332,  2.0713,  0.7616,  0.0083],\n",
              "          [-0.3798,  0.6753, -0.1085, -0.0209, -0.0969],\n",
              "          [-0.0413,  0.5877, -0.2506,  0.8145, -1.6954],\n",
              "          [-0.6602, -0.2511,  0.8644, -0.0166,  0.5895]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv7EDvYsUzUA"
      },
      "source": [
        "##### So sometimes the RGB channels are in dimension 0, and sometimes they are in dimension 1. But we can generalize by counting from the end: they are always in dimension –3, the third from the end.\n",
        "\n",
        "#### The lazy, unweighted mean can thus be written as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moFmenQCVVhn",
        "outputId": "f9eb4723-cfa6-49cc-878f-3cacb16218a1"
      },
      "source": [
        "img_gray_naive = img_t.mean(-3)\n",
        "batch_gray_naive = batch_t.mean(-3)\n",
        "img_gray_naive.shape, batch_gray_naive.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2kOUcbkV5Bt"
      },
      "source": [
        "##### But now we have the weight, too. PyTorch will allow us to multiply things that are the same shape, as well as shapes where one operand is of size 1 in a given dimension. It also appends leading dimensions of size 1 automatically. This is a feature called broadcasting. batch_t of shape (2, 3, 5, 5) is multiplied by unsqueezed_weights of shape (3,1, 1), resulting in a tensor of shape (2, 3, 5, 5), from which we can then sum the third dimension from the end (the three channels):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naon4yTeWtFH",
        "outputId": "83139503-c552-4ab6-e8ea-7654b3f706aa"
      },
      "source": [
        "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
        "img_weights = (img_t * unsqueezed_weights)\n",
        "batch_weights = (batch_t * unsqueezed_weights)\n",
        "img_gray_weighted = img_weights.sum(-3)\n",
        "batch_gray_weighted = batch_weights.sum(-3)\n",
        "batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwzX3C4cYXgu"
      },
      "source": [
        "##### As often in Python, broadcasting—a form of summarizing unnamed things—is done using three dots '...' ; but don’t worry too much about einsum , because we will not use it in the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tarMxKDwYukf",
        "outputId": "b36f023b-e052-426a-f279-1eaf5cb5aa68"
      },
      "source": [
        "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
        "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
        "batch_gray_weighted_fancy.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxyJQXy9Y08T"
      },
      "source": [
        "##### There's lot of bookkeeping involved so Named Tensors came to resue in pytorch version 1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOxaFt5rZGJA"
      },
      "source": [
        "### Tensor factory functions such as tensor and rand take a names argument. \n",
        "The names should be a sequence of strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7sSZbR-drD2",
        "outputId": "552d5d0d-3846-424f-bff6-229e8eab9ed6"
      },
      "source": [
        "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
        "weights_named"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:848.)\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Wo3Mz8eOk-",
        "outputId": "0fdc959b-4205-4082-df8b-6e5dc26787c7"
      },
      "source": [
        "# When we already have a tensor and want to add names (but not change existing ones), we can call the method refine_names on it.\n",
        "# Similar to indexing, the ellipsis ( ...) allows you to leave out any number of dimensions\n",
        "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
        "print(\"img named:\", img_named.shape, img_named.names)\n",
        "print(\"batch named:\", batch_named.shape, batch_named.name)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
            "batch named: torch.Size([2, 3, 5, 5]) None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwWSXlO-gMLf",
        "outputId": "ec466226-5116-477a-d1fe-a09601d5a612"
      },
      "source": [
        "# The method align_as returns a tensor with missing \n",
        "# dimensions added and existing ones permuted to the right order:\n",
        "weights_aligned = weights_named.align_as(img_named)\n",
        "weights_aligned.shape, weights_aligned.names"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 1, 1]), ('channels', 'rows', 'columns'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QO3qT0ChzCl",
        "outputId": "473fe267-ee67-4650-94c4-1e847b6e4014"
      },
      "source": [
        "# Functions accepting dimension arguments, like sum , also take named dimensions:\n",
        "gray_named = (img_named * weights_aligned).sum('channels')\n",
        "gray_named.shape, gray_named.names"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5, 5]), ('rows', 'columns'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15O6BRv1iVsG"
      },
      "source": [
        "#### Named tensors have the potential to eliminate many sources of alignment errors, which—if the PyTorch forum is any indication—can be a source of headaches. It will be interesting to see how widely they will be adopted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceMAC7NPjHPp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}